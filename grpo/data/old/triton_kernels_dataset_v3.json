[
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that computes gelu of a 1D tensor of size N\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef gelu_kernel(\n    x_ptr,  # *Pointer* to input vector\n    output_ptr,  # *Pointer* to output vector\n    N,  # Size of the vector\n    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n):\n    # We need to make multiple \"programs\" for the given size vector.\n    # So we will compute multiple elements in each \"program\".\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    x = tl.load(x_ptr + offsets, mask=mask)\n    # GELU activation: 0.5 * x * (1 + erf(x / sqrt(2)))\n    cdf = 0.5 * (1.0 + tl.math.erf(x / tl.sqrt(2.0)))\n    output = x * cdf\n    tl.store(output_ptr + offsets, output, mask=mask)\n\ndef gelu(x):\n    N = x.numel()\n    output = torch.empty_like(x)\n    # We need to grid the BLOCK_SIZE to cover the entire vector\n    grid = lambda meta: (triton.cdiv(N, meta['BLOCK_SIZE']),)\n    gelu_kernel[grid](x, output, N, BLOCK_SIZE=1024)\n    return output\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef gelu_kernel(\n    x_ptr,  # *Pointer* to input vector\n    output_ptr,  # *Pointer* to output vector\n    N,  # Size of the vector\n    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n):\n    # We need to make multiple \"programs\" for the given size vector.\n    # So we will compute multiple elements in each \"program\".\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    x = tl.load(x_ptr + offsets, mask=mask)\n    # GELU activation: 0.5 * x * (1 + erf(x / sqrt(2)))\n    cdf = 0.5 * (1.0 + tl.math.erf(x / tl.sqrt(2.0)))\n    output = x * cdf\n    tl.store(output_ptr + offsets, output, mask=mask)\n\ndef gelu(x):\n    N = x.numel()\n    output = torch.empty_like(x)\n    # We need to grid the BLOCK_SIZE to cover the entire vector\n    grid = lambda meta: (triton.cdiv(N, meta['BLOCK_SIZE']),)\n    gelu_kernel[grid](x, output, N, BLOCK_SIZE=1024)\n    return output",
    "operation": "gelu",
    "input_shapes": [
      [
        4096
      ]
    ],
    "output_shape": [
      4096
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that performs element-wise divide of two 1D tensors of size N\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef elementwise_divide_kernel(\n    x_ptr, y_ptr, output_ptr, N, \n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    \n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    \n    # Avoid division by zero\n    y = tl.where(y == 0, tl.full_like(y, float('nan')), y)\n    \n    output = x / y\n    tl.store(output_ptr + offsets, output, mask=mask)\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef elementwise_divide_kernel(\n    x_ptr, y_ptr, output_ptr, N, \n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    \n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    \n    # Avoid division by zero\n    y = tl.where(y == 0, tl.full_like(y, float('nan')), y)\n    \n    output = x / y\n    tl.store(output_ptr + offsets, output, mask=mask)",
    "operation": "divide",
    "input_shapes": [
      [
        32768
      ],
      [
        32768
      ]
    ],
    "output_shape": [
      32768
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that performs element-wise subtract of two 1D tensors of size N with efficient memory access patterns\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef subtract_kernel(\n    x_ptr, \n    y_ptr, \n    output_ptr, \n    N, \n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    \n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    \n    result = x - y\n    \n    tl.store(output_ptr + offsets, result, mask=mask)\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef subtract_kernel(\n    x_ptr, \n    y_ptr, \n    output_ptr, \n    N, \n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < N\n    \n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    \n    result = x - y\n    \n    tl.store(output_ptr + offsets, result, mask=mask)",
    "operation": "subtract",
    "input_shapes": [
      [
        4096
      ],
      [
        4096
      ]
    ],
    "output_shape": [
      4096
    ],
    "optimization_level": "basic",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that computes the mean reduction along the last dimension of a 2D tensor with shape [M, N]\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    X_ptr,  # Pointer to input tensor\n    Y_ptr,  # Pointer to output tensor\n    M,      # Number of rows in input tensor\n    N,      # Number of columns in input tensor\n    stride_xm,  # Stride of input tensor along M dimension\n    stride_xn,  # Stride of input tensor along N dimension\n    stride_y,   # Stride of output tensor\n    BLOCK_SIZE_N: tl.constexpr,  # Block size along N dimension\n):\n    # Get the row index\n    row_idx = tl.program_id(0)\n\n    # Calculate the base index for the current row\n    x_ptr = X_ptr + row_idx * stride_xm\n\n    # Initialize accumulator\n    acc = tl.zeros((1,), dtype=tl.float32)\n\n    # Compute the mean\n    for n_offset in range(0, N, BLOCK_SIZE_N):\n        # Calculate the column index\n        col_idx = n_offset + tl.arange(0, BLOCK_SIZE_N)\n\n        # Load the elements from the current row\n        mask = col_idx < N\n        x = tl.load(x_ptr + col_idx * stride_xn, mask=mask, other=0.0)\n\n        # Accumulate the elements\n        acc += tl.sum(x, axis=0)\n\n    # Calculate the mean\n    mean = acc / N\n\n    # Store the result\n    tl.store(Y_ptr + row_idx * stride_y, mean)\n\ndef mean_reduction(X):\n    M, N = X.shape\n    Y = torch.empty(M, device=X.device, dtype=torch.float32)\n\n    # Define the grid and block size\n    grid = lambda META: (M, )\n    BLOCK_SIZE_N = 256\n\n    # Launch the kernel\n    mean_reduction_kernel[grid](\n        X, Y, M, N, \n        X.stride(0), X.stride(1), Y.stride(0), \n        BLOCK_SIZE_N=BLOCK_SIZE_N\n    )\n    return Y\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    X_ptr,  # Pointer to input tensor\n    Y_ptr,  # Pointer to output tensor\n    M,      # Number of rows in input tensor\n    N,      # Number of columns in input tensor\n    stride_xm,  # Stride of input tensor along M dimension\n    stride_xn,  # Stride of input tensor along N dimension\n    stride_y,   # Stride of output tensor\n    BLOCK_SIZE_N: tl.constexpr,  # Block size along N dimension\n):\n    # Get the row index\n    row_idx = tl.program_id(0)\n\n    # Calculate the base index for the current row\n    x_ptr = X_ptr + row_idx * stride_xm\n\n    # Initialize accumulator\n    acc = tl.zeros((1,), dtype=tl.float32)\n\n    # Compute the mean\n    for n_offset in range(0, N, BLOCK_SIZE_N):\n        # Calculate the column index\n        col_idx = n_offset + tl.arange(0, BLOCK_SIZE_N)\n\n        # Load the elements from the current row\n        mask = col_idx < N\n        x = tl.load(x_ptr + col_idx * stride_xn, mask=mask, other=0.0)\n\n        # Accumulate the elements\n        acc += tl.sum(x, axis=0)\n\n    # Calculate the mean\n    mean = acc / N\n\n    # Store the result\n    tl.store(Y_ptr + row_idx * stride_y, mean)\n\ndef mean_reduction(X):\n    M, N = X.shape\n    Y = torch.empty(M, device=X.device, dtype=torch.float32)\n\n    # Define the grid and block size\n    grid = lambda META: (M, )\n    BLOCK_SIZE_N = 256\n\n    # Launch the kernel\n    mean_reduction_kernel[grid](\n        X, Y, M, N, \n        X.stride(0), X.stride(1), Y.stride(0), \n        BLOCK_SIZE_N=BLOCK_SIZE_N\n    )\n    return Y",
    "operation": "mean_reduction",
    "input_shapes": [
      [
        512,
        512
      ]
    ],
    "output_shape": [
      512
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that computes the mean reduction along the last dimension of a 2D tensor with shape [M, N]\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    X_ptr,  # input tensor\n    Y_ptr,  # output tensor\n    M,      # number of rows in X\n    N,      # number of columns in X\n    stride_xm,  # stride of X along M dimension\n    stride_xn,  # stride of X along N dimension\n    stride_ym,  # stride of Y along M dimension\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_block_idx = tl.program_id(1)\n\n    # Calculate the offset for the current row\n    row_offset = row_idx * stride_xm\n\n    # Calculate the base offset for the current column block\n    col_block_offset = col_block_idx * BLOCK_SIZE_N * stride_xn\n\n    # Initialize accumulator\n    accumulator = tl.zeros([1], dtype=tl.float32)\n\n    # Loop over the columns in blocks\n    for col_idx in range(0, N, BLOCK_SIZE_N):\n        col_offset = col_block_offset + col_idx * stride_xn\n        mask = col_idx + tl.arange(0, BLOCK_SIZE_N) < N\n\n        # Load the data for the current column block\n        x = tl.load(X_ptr + row_offset + col_offset, mask=mask, other=0.0)\n\n        # Accumulate the sum\n        accumulator += tl.sum(x, axis=0)\n\n    # Calculate the mean\n    mean = accumulator / N\n\n    # Store the result\n    tl.store(Y_ptr + row_idx * stride_ym, mean)\n\ndef mean_reduction(X):\n    M, N = X.shape\n    Y = torch.empty(M, device=X.device, dtype=torch.float32)\n\n    # Define the grid and block size\n    BLOCK_SIZE_N = 256\n    grid = lambda META: (\n        M,\n        triton.cdiv(N, BLOCK_SIZE_N),\n    )\n\n    mean_reduction_kernel[grid](\n        X, Y, M, N,\n        X.stride(0), X.stride(1),\n        Y.stride(0),\n        BLOCK_SIZE_N=BLOCK_SIZE_N,\n    )\n    return Y\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    X_ptr,  # input tensor\n    Y_ptr,  # output tensor\n    M,      # number of rows in X\n    N,      # number of columns in X\n    stride_xm,  # stride of X along M dimension\n    stride_xn,  # stride of X along N dimension\n    stride_ym,  # stride of Y along M dimension\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_block_idx = tl.program_id(1)\n\n    # Calculate the offset for the current row\n    row_offset = row_idx * stride_xm\n\n    # Calculate the base offset for the current column block\n    col_block_offset = col_block_idx * BLOCK_SIZE_N * stride_xn\n\n    # Initialize accumulator\n    accumulator = tl.zeros([1], dtype=tl.float32)\n\n    # Loop over the columns in blocks\n    for col_idx in range(0, N, BLOCK_SIZE_N):\n        col_offset = col_block_offset + col_idx * stride_xn\n        mask = col_idx + tl.arange(0, BLOCK_SIZE_N) < N\n\n        # Load the data for the current column block\n        x = tl.load(X_ptr + row_offset + col_offset, mask=mask, other=0.0)\n\n        # Accumulate the sum\n        accumulator += tl.sum(x, axis=0)\n\n    # Calculate the mean\n    mean = accumulator / N\n\n    # Store the result\n    tl.store(Y_ptr + row_idx * stride_ym, mean)\n\ndef mean_reduction(X):\n    M, N = X.shape\n    Y = torch.empty(M, device=X.device, dtype=torch.float32)\n\n    # Define the grid and block size\n    BLOCK_SIZE_N = 256\n    grid = lambda META: (\n        M,\n        triton.cdiv(N, BLOCK_SIZE_N),\n    )\n\n    mean_reduction_kernel[grid](\n        X, Y, M, N,\n        X.stride(0), X.stride(1),\n        Y.stride(0),\n        BLOCK_SIZE_N=BLOCK_SIZE_N,\n    )\n    return Y",
    "operation": "mean_reduction",
    "input_shapes": [
      [
        512,
        512
      ]
    ],
    "output_shape": [
      512
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel that computes the mean reduction along the last dimension of a 2D tensor with shape [M, N]\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    input_ptr, output_ptr, \n    M, N, \n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr\n):\n    pid_m = tl.program_id(axis=0)\n    pid_n = tl.program_id(axis=1)\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    mask_m = offs_m < M\n    mask_n = offs_n < N\n\n    acc = tl.zeros((BLOCK_SIZE_M,), dtype=tl.float32)\n\n    for _ in range(0, N, BLOCK_SIZE_N):\n        curr_offs_n = offs_n[:, None] + _ \n        mask = mask_m[:, None] & (curr_offs_n < N)\n        curr_offs = offs_m[:, None] * N + curr_offs_n\n        acc += tl.sum(tl.load(input_ptr + curr_offs, mask=mask, other=0.0), axis=1)\n\n    mean = acc / N\n    offs_out = offs_m\n    tl.store(output_ptr + offs_out, mean, mask=mask_m)\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef mean_reduction_kernel(\n    input_ptr, output_ptr, \n    M, N, \n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr\n):\n    pid_m = tl.program_id(axis=0)\n    pid_n = tl.program_id(axis=1)\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    mask_m = offs_m < M\n    mask_n = offs_n < N\n\n    acc = tl.zeros((BLOCK_SIZE_M,), dtype=tl.float32)\n\n    for _ in range(0, N, BLOCK_SIZE_N):\n        curr_offs_n = offs_n[:, None] + _ \n        mask = mask_m[:, None] & (curr_offs_n < N)\n        curr_offs = offs_m[:, None] * N + curr_offs_n\n        acc += tl.sum(tl.load(input_ptr + curr_offs, mask=mask, other=0.0), axis=1)\n\n    mean = acc / N\n    offs_out = offs_m\n    tl.store(output_ptr + offs_out, mean, mask=mask_m)",
    "operation": "mean_reduction",
    "input_shapes": [
      [
        128,
        128
      ]
    ],
    "output_shape": [
      128
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel for matrix multiplication of tensors with shapes [M, K] and [K, N]\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 256\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    A_ptr, B_ptr, C_ptr,\n    M, N, K,\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    **meta\n):\n    # Define program ID and grid dimensions\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n\n    # Calculate block IDs\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    # Initialize accumulators\n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    for k in range(0, K, BLOCK_SIZE_K):\n        # Load A and B blocks with masking\n        a_ptrs = A_ptr + (offs_m[:, None] * stride_am + (k + offs_k[None, :]) * stride_ak)\n        b_ptrs = B_ptr + ((k + offs_k[:, None]) * stride_bk + offs_n[None, :] * stride_bn)\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (k + offs_k[None, :] < K), other=0.0)\n        b = tl.load(b_ptrs, mask=(k + offs_k[:, None] < K) & (offs_n[None, :] < N), other=0.0)\n\n        # Perform dot product\n        acc += tl.dot(a, b)\n\n    # Store result with masking\n    c_ptrs = C_ptr + (offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn)\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 256\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    A_ptr, B_ptr, C_ptr,\n    M, N, K,\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    **meta\n):\n    # Define program ID and grid dimensions\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n\n    # Calculate block IDs\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    # Initialize accumulators\n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    for k in range(0, K, BLOCK_SIZE_K):\n        # Load A and B blocks with masking\n        a_ptrs = A_ptr + (offs_m[:, None] * stride_am + (k + offs_k[None, :]) * stride_ak)\n        b_ptrs = B_ptr + ((k + offs_k[:, None]) * stride_bk + offs_n[None, :] * stride_bn)\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (k + offs_k[None, :] < K), other=0.0)\n        b = tl.load(b_ptrs, mask=(k + offs_k[:, None] < K) & (offs_n[None, :] < N), other=0.0)\n\n        # Perform dot product\n        acc += tl.dot(a, b)\n\n    # Store result with masking\n    c_ptrs = C_ptr + (offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn)\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))",
    "operation": "matmul",
    "input_shapes": [
      [
        512,
        256
      ],
      [
        256,
        512
      ]
    ],
    "output_shape": [
      512,
      512
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel for matrix multiplication of tensors with shapes [M, K] and [K, N] using tile-based computation with shared memory\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 256\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    # Pointers to matrices\n    a_ptr, b_ptr, c_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    # Meta-parameters\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Extract program IDs\n    pid_m = tl.program_id(axis=0)\n    pid_n = tl.program_id(axis=1)\n\n    # Calculate block IDs\n    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Initialize pointers to A, B, and C blocks\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n    # Initialize accumulator for the result\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        # Load A and B blocks with masking\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n\n        # Perform computation\n        accumulator += tl.dot(a, b)\n\n        # Move pointers to the next block\n        a_ptrs += BLOCK_SIZE_K * stride_ak\n        b_ptrs += BLOCK_SIZE_K * stride_bk\n\n    # Store the result\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n    tl.store(c_ptrs, accumulator, mask=c_mask)\n\ndef matmul(a, b):\n    # Get shapes\n    M, K = a.shape\n    K, N = b.shape\n\n    # Allocate output\n    c = torch.empty((M, N), device=a.device, dtype=torch.float32)\n\n    # Define grid\n    grid = lambda META: (\n        triton.cdiv(M, META['BLOCK_SIZE_M']),\n        triton.cdiv(N, META['BLOCK_SIZE_N']),\n    )\n\n    # Launch kernel\n    matmul_kernel[grid](\n        a, b, c, M, N, K,\n        a.stride(0), a.stride(1), b.stride(0), b.stride(1), c.stride(0), c.stride(1),\n        BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N, BLOCK_SIZE_K=BLOCK_SIZE_K,\n    )\n    return c\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 256\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    # Pointers to matrices\n    a_ptr, b_ptr, c_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    # Meta-parameters\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Extract program IDs\n    pid_m = tl.program_id(axis=0)\n    pid_n = tl.program_id(axis=1)\n\n    # Calculate block IDs\n    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Initialize pointers to A, B, and C blocks\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n    # Initialize accumulator for the result\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        # Load A and B blocks with masking\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n\n        # Perform computation\n        accumulator += tl.dot(a, b)\n\n        # Move pointers to the next block\n        a_ptrs += BLOCK_SIZE_K * stride_ak\n        b_ptrs += BLOCK_SIZE_K * stride_bk\n\n    # Store the result\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n    tl.store(c_ptrs, accumulator, mask=c_mask)\n\ndef matmul(a, b):\n    # Get shapes\n    M, K = a.shape\n    K, N = b.shape\n\n    # Allocate output\n    c = torch.empty((M, N), device=a.device, dtype=torch.float32)\n\n    # Define grid\n    grid = lambda META: (\n        triton.cdiv(M, META['BLOCK_SIZE_M']),\n        triton.cdiv(N, META['BLOCK_SIZE_N']),\n    )\n\n    # Launch kernel\n    matmul_kernel[grid](\n        a, b, c, M, N, K,\n        a.stride(0), a.stride(1), b.stride(0), b.stride(1), c.stride(0), c.stride(1),\n        BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N, BLOCK_SIZE_K=BLOCK_SIZE_K,\n    )\n    return c",
    "operation": "matmul",
    "input_shapes": [
      [
        256,
        256
      ],
      [
        256,
        128
      ]
    ],
    "output_shape": [
      256,
      128
    ],
    "optimization_level": "basic",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  },
  {
    "prompt": "You are an expert at writing high-performance Triton kernels.\n\nTask: Write a Triton kernel for matrix multiplication of tensors with shapes [M, K] and [K, N]\n\nRequirements:\n- Write clean, efficient Triton code\n- Include proper imports (triton, triton.language as tl)\n- Use appropriate BLOCK_SIZE constants\n- Handle edge cases with proper masking\n- Include the @triton.jit decorator\n\nProvide only the kernel code without explanation.",
    "response": "```python\nimport triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 128\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    A_ptr, B_ptr, C_ptr,\n    M, N, K,\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    **meta\n):\n    # Define program ID and grid dimensions\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n\n    # Calculate block IDs\n    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Initialize accumulators\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    for k in range(0, K, BLOCK_SIZE_K):\n        offs_ak = k + offs_k\n        offs_bk = k + offs_k\n\n        # Load A and B blocks with masking\n        a_ptrs = A_ptr + (offs_am[:, None] * stride_am + offs_ak[None, :] * stride_ak)\n        b_ptrs = B_ptr + (offs_bk[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n        a = tl.load(a_ptrs, mask=(offs_am[:, None] < M) & (offs_ak[None, :] < K), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_bk[:, None] < K) & (offs_bn[None, :] < N), other=0.0)\n\n        # Perform dot product\n        accumulator += tl.dot(a, b)\n\n    # Store result with masking\n    c_ptrs = C_ptr + (offs_am[:, None] * stride_cm + offs_bn[None, :] * stride_cn)\n    tl.store(c_ptrs, accumulator, mask=(offs_am[:, None] < M) & (offs_bn[None, :] < N))\n```",
    "kernel_code": "import triton\nimport triton.language as tl\n\n# Define constants for block sizes\nBLOCK_SIZE_M = 128\nBLOCK_SIZE_N = 128\nBLOCK_SIZE_K = 32\n\n@triton.jit\ndef matmul_kernel(\n    A_ptr, B_ptr, C_ptr,\n    M, N, K,\n    stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn,\n    **meta\n):\n    # Define program ID and grid dimensions\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n\n    # Calculate block IDs\n    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Initialize accumulators\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    # Iterate over K dimension\n    for k in range(0, K, BLOCK_SIZE_K):\n        offs_ak = k + offs_k\n        offs_bk = k + offs_k\n\n        # Load A and B blocks with masking\n        a_ptrs = A_ptr + (offs_am[:, None] * stride_am + offs_ak[None, :] * stride_ak)\n        b_ptrs = B_ptr + (offs_bk[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n        a = tl.load(a_ptrs, mask=(offs_am[:, None] < M) & (offs_ak[None, :] < K), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_bk[:, None] < K) & (offs_bn[None, :] < N), other=0.0)\n\n        # Perform dot product\n        accumulator += tl.dot(a, b)\n\n    # Store result with masking\n    c_ptrs = C_ptr + (offs_am[:, None] * stride_cm + offs_bn[None, :] * stride_cn)\n    tl.store(c_ptrs, accumulator, mask=(offs_am[:, None] < M) & (offs_bn[None, :] < N))",
    "operation": "matmul",
    "input_shapes": [
      [
        256,
        256
      ],
      [
        256,
        128
      ]
    ],
    "output_shape": [
      256,
      128
    ],
    "optimization_level": "none",
    "compiles": false,
    "error_message": "No @triton.jit decorated function found"
  }
]